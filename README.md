# ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù„Ø§Ø²Ù…Ø©
!pip install openai-whisper transformers torchaudio librosa soundfile matplotlib

import whisper
from transformers import pipeline
import matplotlib.pyplot as plt
import IPython.display as ipd
from google.colab import files

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Whisper
asr_model = whisper.load_model("base")

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
sentiment_pipeline = pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")

# Ø±ÙØ¹ Ù…Ù„Ù ØµÙˆØªÙŠ
uploaded = files.upload()
audio_path = list(uploaded.keys())[0]

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ù„Ù
print(f"ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {audio_path}")
ipd.display(ipd.Audio(audio_path))

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ
print("ğŸ”„ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ...")
result = asr_model.transcribe(audio_path)
text = result['text']
print("âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ:")
print(text)

# ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
print("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±...")
sentiment = sentiment_pipeline(text)
print("âœ… Ø§Ù„Ù†ØªÙŠØ¬Ø©:")
print(sentiment)

# Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ
labels = [s['label'] for s in sentiment]
scores = [s['score'] for s in sentiment]

plt.bar(labels, scores, color='skyblue')
plt.xlabel("Ù†ÙˆØ¹ Ø§Ù„Ø´Ø¹ÙˆØ±")
plt.ylabel("Ø§Ù„Ø¯Ø±Ø¬Ø©")
plt.title("ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±")
plt.show()
